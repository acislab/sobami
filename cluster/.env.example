HF_TOKEN=
# Ray Configurations
RAY_HEAD_NODE_IP=
RAY_HEAD_NODE_PORT=3002
RAY_DASHBOARD_HOST=0.0.0.0
RAY_DASHBOARD_PORT=5678
RAY_HEAD_ETHERNET_DEVICE=
# Resources Allocation
# GPUs
RAY_HEAD_GPU_COUNT=
RAY_WORKER_1_ETHERNET_DEVICE=
RAY_WORKER_1_GPU_COUNT=
# Container Shared Memory
SHM_SIZE=16gb
# Ray[Manager, Worker] System Resources
MEMORY_SIZE=32gb
CPUS=8
# Other Services System Resources
SERVICE_CPUS=4
SERVICE_MEMORY=16gb
# vLLM Server Configurations
MODEL=meta-llama/Llama-3.2-1B-Instruct
# Container Configurations
SWARM_MANAGER_DOCKER_IMAGE=vllm/vllm-openai:v0.6.6
SWARM_MANAGER_PATH_TO_HF_HOME=~/.cache/huggingface
SWARM_MANAGER_PATH_TO_TMP_RAY=~/tmp/ray
SWARM_WORKER_DOCKER_IMAGE=vllm/vllm-openai:v0.6.6
SWARM_WORKER_PATH_TO_HF_HOME=~/.cache/huggingface
SWARM_WORKER_PATH_TO_TMP_RAY=~/tmp/ray
# Prometheus Container Configurations
PROMETHEUS_DOCKER_IMAGE=prom/prometheus:latest
PROMETHEUS_PATH_TO_STORAGE=~/storage/tmp/prometheus
PROMETHEUS_CONFIG_PATH=~/nitingoyal/sobami/cluster/configs
PROMETHEUS_RAY_DISCOVERY_JSON_PATH=~/storage/tmp/ray/prom_metrics_service_discovery.json
